{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification and Hidden Markov Models.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOvPMU6EZtzObqfz8It1Cuh"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"SyNi33ZaFBof","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594653632801,"user_tz":300,"elapsed":439,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qkMXp-T3FHkU","colab_type":"text"},"source":["# **Classification**\n","\n","Classification is used to separate data points into classes of different labels. In this example we will be using Tensorflow estimtor to classify flowers based on the Iris Dataset\n","\n","This is based on the Tensorflow website https://www.tensorflow.org/tutorials/estimator/premade\n"]},{"cell_type":"markdown","metadata":{"id":"7QTQBYPMF45W","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"H7FIMgUHF696","colab_type":"text"},"source":["# **Imports and Setup**"]},{"cell_type":"code","metadata":{"id":"OnDQPoWxGAHn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1594653632916,"user_tz":300,"elapsed":538,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"fd270b8c-49d4-46e5-8760-f6c1078d08db"},"source":["%tensorflow_version 2.x # this line is not required unless you are in a notebook"],"execution_count":1,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `2.x # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n","\n","\n","TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dvCxvWReGric","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594653634514,"user_tz":300,"elapsed":2134,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import tensorflow as tf\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ql8SKekZOplX","colab_type":"text"},"source":["Dataset \n","\n","This specific dataset separates flowers into 3 different classes of species\n","*   Setosa\n","*   Versicolor\n","*   Virginica\n","\n","The information about the flowers are:\n","*   sepal length\n","*   petal length\n","*   sepal width\n","*   petal width"]},{"cell_type":"code","metadata":{"id":"Fg-tQ8bZP5zs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594653634515,"user_tz":300,"elapsed":2132,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["# Define some constants\n","CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n","SPECIES = ['Setosa', 'Versicolor', 'Virginica']"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"we00HJ9YQOFw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1594653634676,"user_tz":300,"elapsed":2287,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"6949ac81-7f39-4d05-fab1-f300a7597961"},"source":["train_path = tf.keras.utils.get_file(\n","    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n","test_path = tf.keras.utils.get_file(\n","    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n","8192/2194 [================================================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n","8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HfH-1ekVQ3sX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594653634680,"user_tz":300,"elapsed":2288,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["train = pd.read_csv(train_path, names = CSV_COLUMN_NAMES, header = 0)\n","test = pd.read_csv(test_path, names = CSV_COLUMN_NAMES, header = 0)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_DmWdvnSi_l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1594653635132,"user_tz":300,"elapsed":2734,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"cf6e07dc-8ea9-471b-eadc-1b25888f08d8"},"source":["train.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SepalLength</th>\n","      <th>SepalWidth</th>\n","      <th>PetalLength</th>\n","      <th>PetalWidth</th>\n","      <th>Species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.4</td>\n","      <td>2.8</td>\n","      <td>5.6</td>\n","      <td>2.2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>2.3</td>\n","      <td>3.3</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.9</td>\n","      <td>2.5</td>\n","      <td>4.5</td>\n","      <td>1.7</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.9</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.7</td>\n","      <td>3.8</td>\n","      <td>1.7</td>\n","      <td>0.3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n","0          6.4         2.8          5.6         2.2        2\n","1          5.0         2.3          3.3         1.0        1\n","2          4.9         2.5          4.5         1.7        2\n","3          4.9         3.1          1.5         0.1        0\n","4          5.7         3.8          1.7         0.3        0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"emQctiqVS6eb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594653635133,"user_tz":300,"elapsed":2733,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["train_y = train.pop('Species')\n","test_y = test.pop('Species')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nodsHk7cTGP0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1594653635135,"user_tz":300,"elapsed":2729,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"ea8cc9db-935a-40bc-ee03-2b2eaa58d394"},"source":["#train_y.head()\n","train.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SepalLength</th>\n","      <th>SepalWidth</th>\n","      <th>PetalLength</th>\n","      <th>PetalWidth</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.4</td>\n","      <td>2.8</td>\n","      <td>5.6</td>\n","      <td>2.2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>2.3</td>\n","      <td>3.3</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.9</td>\n","      <td>2.5</td>\n","      <td>4.5</td>\n","      <td>1.7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.9</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.7</td>\n","      <td>3.8</td>\n","      <td>1.7</td>\n","      <td>0.3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   SepalLength  SepalWidth  PetalLength  PetalWidth\n","0          6.4         2.8          5.6         2.2\n","1          5.0         2.3          3.3         1.0\n","2          4.9         2.5          4.5         1.7\n","3          4.9         3.1          1.5         0.1\n","4          5.7         3.8          1.7         0.3"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"f6Q3HrsPTRcR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594653635136,"user_tz":300,"elapsed":2724,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"f3d412ab-8aa9-424d-dbee-63045b6e37f3"},"source":["train.shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(120, 4)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"pE3nMb11TaOt","colab_type":"text"},"source":["Input Function\n","\n","We now define a model using a Tensorflow Estimator. An Estimator is any class derived from the tf.estimator.Estimator. \n","\n","To write a Tensorflow program based on  pre-made Estimators, perform the following tasks:\n","\n","\n","*   Create one or more input functions\n","*   Define the model's feature columns   \n","*   Instantiate an Estimator, specifying the feature columns and various hyperparameters.\n","*   Call one or more methods on the Estimator object, passing the appropriate input function as the source of the data.\n","\n","An input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:\n","\n","features - A Python dictionary in which:\n","\n","*   Each key is the name of a feature\n","*   Each value is an array containing all of that feature's values.\n","\n","label - An array containing the values of the label for every example\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"JOnbeG1trFiT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594653635136,"user_tz":300,"elapsed":2722,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["# #Just to demonstrate the format of the input function, here's a simple implementation\n","# def input_evaluation_set():\n","#     features = {'SepalLength': np.array([6.4, 5.0]),\n","#                 'SepalWidth':  np.array([2.8, 2.3]),\n","#                 'PetalLength': np.array([5.6, 3.3]),\n","#                 'PetalWidth':  np.array([2.2, 1.0])}\n","#     labels = np.array([2, 1])\n","#     return features, labels"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1v5W4cRVs5Iq","colab_type":"text"},"source":["Tensorflow's Dataset API (https://www.tensorflow.org/guide/data) can handle a lot of common cases for you. For example, using the Dataset API, you can easily read in records from a large collection of files in parallel and join them into a single stream. \n","\n","To keep things simple we are going to load the data with pandas, and built an input pipeline"]},{"cell_type":"markdown","metadata":{"id":"rEEwRlSvszF6","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"QeHXXO1826dY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594653635137,"user_tz":300,"elapsed":2721,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["def input_fn(features, labels, training = True, batch_size = 256):\n","  #Converts the inputs to a Dataset\n","  dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n","\n","  #Shuffle and repeat if you are in training mode\n","  if training:\n","    dataset = dataset.shuffle(1000).repeat()\n","\n","  return dataset.batch(batch_size)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZXNu_HgwGy-n","colab_type":"text"},"source":["**Feature Columns**\n"]},{"cell_type":"code","metadata":{"id":"iNCrk8YMHa-y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594653635138,"user_tz":300,"elapsed":2716,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"8115f09f-1844-406c-e7ac-7ecc83ab8735"},"source":["my_feature_columns = []\n","for key in train.keys():\n","  my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n","print(my_feature_columns)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7fvLiCTvIbkQ","colab_type":"text"},"source":["**Building the Model**\n","\n","And now we are ready to choose a model. For classification tasks there are variety of different estimators/models that we can pick from.\n","Some options are:\n","*   DNNClassifier(Deep Neural Network)\n","*   LinearClassifier\n","\n","We would be using DNNClassifier here\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"cXKUHchQJccr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1594653635250,"user_tz":300,"elapsed":2822,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"3b30f7e6-5670-448d-ec50-9805b8c8f2bf"},"source":["classifier = tf.estimator.DNNClassifier(\n","    feature_columns = my_feature_columns,\n","    #Two hidden layers of 30 and 10 nodes respectively\n","    hidden_units=[30,10],\n","    #The model must choose between 3 classes\n","    n_classes=3\n",")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpn3jiwd6e\n","INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpn3jiwd6e', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iEzVILPfKze1","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"-bToodnYK322","colab_type":"text"},"source":["**Training**\n","\n","The steps argument here tells the classifier to run for 5000 steps. Modifying this might change the result. Keep in mind that more is not always better."]},{"cell_type":"code","metadata":{"id":"O2uM8UuENsu6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594653645022,"user_tz":300,"elapsed":12592,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"ae82ed1b-af90-48e2-a670-c2645686f53e"},"source":["classifier.train(\n","    input_fn=lambda: input_fn(train, train_y, training=True),\n","    #lambda is a function and whatever is after the colon is what the lambda function does. What is great about this is that lambda helps to define or call a function in one line\n","    steps=5000\n",")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","INFO:tensorflow:Calling model_fn.\n","WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n","\n","If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n","\n","To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:106: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n","INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpn3jiwd6e/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n","INFO:tensorflow:loss = 1.501723, step = 0\n","INFO:tensorflow:global_step/sec: 475.045\n","INFO:tensorflow:loss = 1.1052364, step = 100 (0.212 sec)\n","INFO:tensorflow:global_step/sec: 652.296\n","INFO:tensorflow:loss = 1.0334135, step = 200 (0.154 sec)\n","INFO:tensorflow:global_step/sec: 643.972\n","INFO:tensorflow:loss = 0.98128617, step = 300 (0.155 sec)\n","INFO:tensorflow:global_step/sec: 601.286\n","INFO:tensorflow:loss = 0.94932973, step = 400 (0.166 sec)\n","INFO:tensorflow:global_step/sec: 632.244\n","INFO:tensorflow:loss = 0.9089049, step = 500 (0.161 sec)\n","INFO:tensorflow:global_step/sec: 621.716\n","INFO:tensorflow:loss = 0.8746282, step = 600 (0.158 sec)\n","INFO:tensorflow:global_step/sec: 616.69\n","INFO:tensorflow:loss = 0.843122, step = 700 (0.162 sec)\n","INFO:tensorflow:global_step/sec: 637.978\n","INFO:tensorflow:loss = 0.8290987, step = 800 (0.159 sec)\n","INFO:tensorflow:global_step/sec: 623.569\n","INFO:tensorflow:loss = 0.8012016, step = 900 (0.158 sec)\n","INFO:tensorflow:global_step/sec: 609.639\n","INFO:tensorflow:loss = 0.77420545, step = 1000 (0.165 sec)\n","INFO:tensorflow:global_step/sec: 636.829\n","INFO:tensorflow:loss = 0.7615764, step = 1100 (0.158 sec)\n","INFO:tensorflow:global_step/sec: 614.716\n","INFO:tensorflow:loss = 0.73491263, step = 1200 (0.161 sec)\n","INFO:tensorflow:global_step/sec: 586.046\n","INFO:tensorflow:loss = 0.71962625, step = 1300 (0.170 sec)\n","INFO:tensorflow:global_step/sec: 661.229\n","INFO:tensorflow:loss = 0.69626, step = 1400 (0.152 sec)\n","INFO:tensorflow:global_step/sec: 649.928\n","INFO:tensorflow:loss = 0.6982518, step = 1500 (0.157 sec)\n","INFO:tensorflow:global_step/sec: 634.709\n","INFO:tensorflow:loss = 0.68138456, step = 1600 (0.157 sec)\n","INFO:tensorflow:global_step/sec: 598.134\n","INFO:tensorflow:loss = 0.6580776, step = 1700 (0.168 sec)\n","INFO:tensorflow:global_step/sec: 608.157\n","INFO:tensorflow:loss = 0.649277, step = 1800 (0.163 sec)\n","INFO:tensorflow:global_step/sec: 622.576\n","INFO:tensorflow:loss = 0.64967453, step = 1900 (0.160 sec)\n","INFO:tensorflow:global_step/sec: 629.324\n","INFO:tensorflow:loss = 0.6291909, step = 2000 (0.162 sec)\n","INFO:tensorflow:global_step/sec: 664.275\n","INFO:tensorflow:loss = 0.612056, step = 2100 (0.150 sec)\n","INFO:tensorflow:global_step/sec: 635.166\n","INFO:tensorflow:loss = 0.60333294, step = 2200 (0.155 sec)\n","INFO:tensorflow:global_step/sec: 652.273\n","INFO:tensorflow:loss = 0.60057425, step = 2300 (0.153 sec)\n","INFO:tensorflow:global_step/sec: 637.611\n","INFO:tensorflow:loss = 0.592214, step = 2400 (0.160 sec)\n","INFO:tensorflow:global_step/sec: 605.522\n","INFO:tensorflow:loss = 0.5675501, step = 2500 (0.166 sec)\n","INFO:tensorflow:global_step/sec: 628.078\n","INFO:tensorflow:loss = 0.5692167, step = 2600 (0.156 sec)\n","INFO:tensorflow:global_step/sec: 607.846\n","INFO:tensorflow:loss = 0.5515125, step = 2700 (0.165 sec)\n","INFO:tensorflow:global_step/sec: 626.627\n","INFO:tensorflow:loss = 0.5476372, step = 2800 (0.160 sec)\n","INFO:tensorflow:global_step/sec: 640.813\n","INFO:tensorflow:loss = 0.51867354, step = 2900 (0.156 sec)\n","INFO:tensorflow:global_step/sec: 568.595\n","INFO:tensorflow:loss = 0.5124468, step = 3000 (0.175 sec)\n","INFO:tensorflow:global_step/sec: 651.584\n","INFO:tensorflow:loss = 0.5179024, step = 3100 (0.157 sec)\n","INFO:tensorflow:global_step/sec: 597.947\n","INFO:tensorflow:loss = 0.49477708, step = 3200 (0.164 sec)\n","INFO:tensorflow:global_step/sec: 646.322\n","INFO:tensorflow:loss = 0.48922992, step = 3300 (0.154 sec)\n","INFO:tensorflow:global_step/sec: 645.362\n","INFO:tensorflow:loss = 0.48007718, step = 3400 (0.155 sec)\n","INFO:tensorflow:global_step/sec: 651.096\n","INFO:tensorflow:loss = 0.4792274, step = 3500 (0.156 sec)\n","INFO:tensorflow:global_step/sec: 630.806\n","INFO:tensorflow:loss = 0.47261953, step = 3600 (0.159 sec)\n","INFO:tensorflow:global_step/sec: 609.09\n","INFO:tensorflow:loss = 0.4661448, step = 3700 (0.162 sec)\n","INFO:tensorflow:global_step/sec: 553.879\n","INFO:tensorflow:loss = 0.4533882, step = 3800 (0.180 sec)\n","INFO:tensorflow:global_step/sec: 645.943\n","INFO:tensorflow:loss = 0.464745, step = 3900 (0.155 sec)\n","INFO:tensorflow:global_step/sec: 656.548\n","INFO:tensorflow:loss = 0.44125563, step = 4000 (0.152 sec)\n","INFO:tensorflow:global_step/sec: 633.7\n","INFO:tensorflow:loss = 0.42522526, step = 4100 (0.158 sec)\n","INFO:tensorflow:global_step/sec: 629.142\n","INFO:tensorflow:loss = 0.44234422, step = 4200 (0.159 sec)\n","INFO:tensorflow:global_step/sec: 647.995\n","INFO:tensorflow:loss = 0.42639285, step = 4300 (0.154 sec)\n","INFO:tensorflow:global_step/sec: 555.645\n","INFO:tensorflow:loss = 0.4175302, step = 4400 (0.180 sec)\n","INFO:tensorflow:global_step/sec: 651.819\n","INFO:tensorflow:loss = 0.4280424, step = 4500 (0.155 sec)\n","INFO:tensorflow:global_step/sec: 655.031\n","INFO:tensorflow:loss = 0.42080972, step = 4600 (0.153 sec)\n","INFO:tensorflow:global_step/sec: 630.885\n","INFO:tensorflow:loss = 0.41751993, step = 4700 (0.159 sec)\n","INFO:tensorflow:global_step/sec: 632.978\n","INFO:tensorflow:loss = 0.41278005, step = 4800 (0.158 sec)\n","INFO:tensorflow:global_step/sec: 604.68\n","INFO:tensorflow:loss = 0.41089034, step = 4900 (0.165 sec)\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n","INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpn3jiwd6e/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n","INFO:tensorflow:Loss for final step: 0.41634798.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f1444d75278>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"tSVYufTkgtHE","colab_type":"text"},"source":["**Evaluation**"]},{"cell_type":"code","metadata":{"id":"scSpn_jYgS5_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":389},"executionInfo":{"status":"ok","timestamp":1594653646047,"user_tz":300,"elapsed":13611,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"0b6d1cd6-7005-4337-b0a1-ac9f6217c201"},"source":["eval_result = classifier.evaluate(input_fn = lambda:input_fn(test, test_y, training = False))\n","print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n","WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n","\n","If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n","\n","To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n","\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-07-13T15:20:45Z\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpn3jiwd6e/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Inference Time : 0.29054s\n","INFO:tensorflow:Finished evaluation at 2020-07-13-15:20:46\n","INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8333333, average_loss = 0.48265857, global_step = 5000, loss = 0.48265857\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpn3jiwd6e/model.ckpt-5000\n","\n","Test set accuracy: 0.833\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A-YAyXAxt1cq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594653646049,"user_tz":300,"elapsed":13607,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"1913df63-54f0-46c5-9e35-e8d07ccab9e6"},"source":["print(eval_result)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["{'accuracy': 0.8333333, 'average_loss': 0.48265857, 'loss': 0.48265857, 'global_step': 5000}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XVZ9raH_IgV3","colab_type":"text"},"source":["**Prediction**"]},{"cell_type":"code","metadata":{"id":"-0WyxN3SIdti","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":266},"executionInfo":{"status":"ok","timestamp":1594654312299,"user_tz":300,"elapsed":679851,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"c212c0e9-3248-40f9-8a48-51a907e14014"},"source":["def input_fn(features, batch_size=256):\n","  # Convert the inputs to a Dataset without label\n","  return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n","\n","\n","features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n","predict = {}\n","\n","print(\"Please type numeric values as prompted\")\n","for feature in features:\n","  valid = True\n","  while valid:\n","    val = input(feature + \":\")\n","    if not val.isdigit(): valid = False\n","\n","  predict[feature] = [float(val)] \n","\n","predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n","for pred_dict in predictions:\n","  print(pred_dict)\n","  class_id = pred_dict['class_ids'][0]\n","  probability = pred_dict['probabilities'][class_id]\n","\n","  print('Prediction is \"{}\" ({:.1f}%)'.format(SPECIES[class_id], 100 * probability))\n","\n","\n","\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Please type numeric values as prompted\n","SepalLength:2.5\n","SepalWidth:2.6\n","PetalLength:4.3\n","PetalWidth:6.2\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpn3jiwd6e/model.ckpt-5000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","{'logits': array([-4.9997745, -0.7402899,  0.7534181], dtype=float32), 'probabilities': array([0.00258419, 0.18289196, 0.8145238 ], dtype=float32), 'class_ids': array([2]), 'classes': array([b'2'], dtype=object), 'all_class_ids': array([0, 1, 2], dtype=int32), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n","Prediction is \"Virginica\" (81.5%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PhuweWrXrGbq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594654312300,"user_tz":300,"elapsed":679850,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["# Here is some example input and expected classes you can try above\n","expected = ['Setosa', 'Versicolor', 'Virginica']\n","predict_x = {\n","    'SepalLength' : [5.1, 5.9, 6.9],\n","    'SepalWidth' : [3.3, 3.0, 3.1],\n","    'PetalLength' : [1.7, 4.2, 5.4],\n","    'PetalWidth' : [0.5, 1.5, 2.1],\n","}"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3eSm2_kBr1JU","colab_type":"text"},"source":["**Clustering**\n","\n","Clustering is a Machine Learning technique that involves the grouping of data points. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features.\n","\n","Unfortunately, there are issues with teh current version of Tensorflow and the implementation for KMeans\n","\n","Basic Algorithm for K-Means. \n","\n","*   Step 1: Randomly pick K points to place K centroids\n","*   Step 2: Assign all of the data points to the centroids by distance. The closest centroid to a point is the one it is assigned to\n","*   Step 3: Average of all of the points belonging t0 find the middle of those clusters (Center of mass). Place the corresponding centroids into that position.\n","*   Step 4: Reaasign every point once again to the closest centroid\n","*   Step 5: Repeat steps 3-4 until no point changes which centroid it belogs to.\n"]},{"cell_type":"markdown","metadata":{"id":"GSYV13Nqv91T","colab_type":"text"},"source":["**Hidden Markov Models**\n","\n","A hidden markov model is a finite set of states, each of which is assoiciated with a (generally multidimensional) probability distribution. Transitions among the states are governed by a set of probabilities called transition probabilities. \n","(http://jedlik.phy.bme.hu/~gerjanos/HMM/node4.html)\n","\n","A hidden markov model works with probabilities to predict future events or states. In this section, we will learn how to create a hidden markov model that can predict the weather.\n","\n","This section is based on the TensorFlow tutorial.\n","https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZTRiGj1PEEyx","colab_type":"text"},"source":["**Data**\n","\n","For a markov model we are only interested in probability distributions that have to do with states. We can find these probabilities with large datasets or may already have these values. \n","\n","States: In each markov model we have a finite set of states. These states could be something like warm and cold or red, blue, green and blue. These states are hidden within the model, which means we do not directly observe them.\n","\n","Observation: Each state has a particular outcome or observation associated with it based on a probability distribution . An example of this is the following:On a hot day Tim has a 80% chance of being happy and a 20% chance of being sad.\n","\n","Transitions: Each state will have a probability of transitioning to a different state. An Example is the following: A cold day has a 30% chance of being followed by a hot day and a 70% chance of being followed by another cold day.\n","\n","To create a hidden markov model we need.\n","\n","*   States\n","*   Observation Distribution\n","*   Transition Distribution\n"]},{"cell_type":"markdown","metadata":{"id":"a9z1xrXWMMtu","colab_type":"text"},"source":["**Imports and Setup**"]},{"cell_type":"code","metadata":{"id":"CZllAzW1MJ2Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594654313158,"user_tz":300,"elapsed":680706,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["import tensorflow_probability as tfp \n","import tensorflow as tf"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-NtaSsmpNTPZ","colab_type":"text"},"source":["Weather model\n","\n","Taken from Tensorflow documentation\n","https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel\n","\n","We will model a simple weather system and try to predict the temperature on each day given the following information:\n","\n","1.   Cold days are encoded by a 0 and hot days are encoded as 1\n","2.   The first day in our sequence has an 80% chance of being cold\n","3.   A cold day has a 30 % chance of being followed by a hot day\n","4.   A hot day has a 20% chance of being followed by a cold day\n","5.   On each day the teamperature is normally distributed with mean and  deviation 0 and 5 on a cold day and mean and devition of 15 and 10 on a hot day."]},{"cell_type":"code","metadata":{"id":"VL4GafnIv82q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594654313159,"user_tz":300,"elapsed":680705,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["tfd = tfp.distributions  # making a shortcut for later on\n","initial_distribution = tfd.Categorical(probs = [0.8, 0.2]) # Refer to point 2 above\n","transition_distribution = tfd.Categorical(probs = [[0.7, 0.3], [0.2, 0.8]]) # Based on point 3 and 4 above\n","observation_distribution = tfd.Normal(loc=[0.,15.], scale=[5.,10.]) # Refer to point 5 above\n","# the loc argument represents the mean and the scale represents the deviation"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zPv61VLCetR0","colab_type":"text"},"source":["We've now created distribution variables to model our system and it's time to create the hidden markov model"]},{"cell_type":"code","metadata":{"id":"ZYSgmCrEeq1V","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594654313160,"user_tz":300,"elapsed":680704,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["model = tfd.HiddenMarkovModel(\n","    initial_distribution=initial_distribution,\n","    transition_distribution = transition_distribution,\n","    observation_distribution = observation_distribution,\n","    num_steps=7)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NNdszBMphueU","colab_type":"text"},"source":["The number of steps represents the number of days that we would like to predict information for. In this case, we have chosen entire week\n","\n","Now to get the expected temperatures on each day we can do the following"]},{"cell_type":"code","metadata":{"id":"eknGbIdPhtjr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594654313160,"user_tz":300,"elapsed":680699,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"88a1b935-859f-4ea4-8f46-3e99fb2726b8"},"source":["mean = model.mean()\n","\n","# due to the way TensorFlow works on a lower level we need to evaluate part of the graph\n","# frokm within a session to see the value of this tensor\n","\n","# in the newer version of TensorFlow we need to use tf.compat.v1.Session() rather than just tf.Session()\n","with tf.compat.v1.Session() as sess:\n","  print(mean.numpy())"],"execution_count":22,"outputs":[{"output_type":"stream","text":["[2.9999998 5.9999995 7.4999995 8.25      8.625001  8.812501  8.90625  ]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vmu2FUffj9f8","colab_type":"text"},"source":["If we run this model for 'n' number of times, we would get similar values."]},{"cell_type":"markdown","metadata":{"id":"FeXnyobZSsME","colab_type":"text"},"source":["**Re-creating with different values and probabilities**"]},{"cell_type":"code","metadata":{"id":"59W29i6OvchF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594654313160,"user_tz":300,"elapsed":680697,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["tfd = tfp.distributions  # making a shortcut for later on\n","initial_distribution = tfd.Categorical(probs = [0.5, 0.5]) # Refer to point 2 above\n","transition_distribution = tfd.Categorical(probs = [[0.7, 0.3], [0.2, 0.8]]) # Based on point 3 and 4 above\n","observation_distribution = tfd.Normal(loc=[0.,15.], scale=[5.,10.]) # Refer to point 5 above\n","# the loc argument represents the mean and the scale represents the deviation"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpHKh12JTBpM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594654313161,"user_tz":300,"elapsed":680696,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":["model = tfd.HiddenMarkovModel(\n","    initial_distribution=initial_distribution,\n","    transition_distribution = transition_distribution,\n","    observation_distribution = observation_distribution,\n","    num_steps=7)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y2zOVgAPTCfL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594654313161,"user_tz":300,"elapsed":680690,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}},"outputId":"1edaff94-19fd-4c42-fc6e-1c1ff2eb46b4"},"source":["mean = model.mean()\n","\n","# due to the way TensorFlow works on a lower level we need to evaluate part of the graph\n","# frokm within a session to see the value of this tensor\n","\n","# in the newer version of TensorFlow we need to use tf.compat.v1.Session() rather than just tf.Session()\n","with tf.compat.v1.Session() as sess:\n","  print(mean.numpy())"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[7.5       8.25      8.625001  8.812501  8.90625   8.953125  8.9765625]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KdukxPGIVfO-","colab_type":"text"},"source":["Conclusion\n","\n","So that's it for the core learning algorithms in TensorFlow. Hopefully, you've learned about a few interesting tools that are pretty easy to use and practice. I'd encourage you to try out some of these algorithms on different datasets."]},{"cell_type":"code","metadata":{"id":"3-RusM0eVeVt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594654313162,"user_tz":300,"elapsed":680689,"user":{"displayName":"Rohit Dutta","photoUrl":"","userId":"12080252758603696122"}}},"source":[""],"execution_count":25,"outputs":[]}]}